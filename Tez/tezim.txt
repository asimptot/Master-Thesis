* generalized assignnment problem
* kendimden bir þeyler katmalýyým, heuristic yaklaþ
* decision tree algoritmalarýndan yürünebilir
* regression<
	
_______________________________________________________

DecisionTreeRegressor

* Tahmin esnasýnda bu aralýktan bir deðer sorulduðunda cevap olarak bu aralýktaki (eðitim esnasýnda öðrendiði) ortalamayý söyleyiveriyor. Bu yüzden lineer gibi deðil, kesikli.
* Veri setini küçük parçalara ayýrýyor.
* Aralýk dýþý bir deðer sorulduðunda aþaðý veya yukarý yuvarlýyor. Kendine en yakýn uzaklýðýn ortalamasýný veriyor.
* Belli bir aralýkta istenen tahminler için ayný sonuçlarý üretir.
* Az verilerde stable. Küçük veri deðiþikliðinde farklý bi aðaç türetilebilir. Instable olabilir yani.
* Recursive


SVR

* 2 sýnýftan oluþan veriyi ayýrmada kullanýlýr. Örn: bir veri sýnýfýndaki her veriyi iyi-kötü diye ayýrmak...
* 2 sýnýf arasý uzaklýðý maksimize ediyoruz. Düzlem þeklinde.
* Baðýmsýz deðiþkenlerin veya verilerin özelliklerinin aralýðýný normalize etmek için kullanýlan bir yöntemdir. 
* Ben kodda standart scaling yaptým.
-> [x-ort(x)]/ss
-> x=15 için (15-35.275)/12.316=-1.64 => yeni grafiðin x'i
-> -1.64'ün y karþýlýðý => -1.87
-> (y' - 49.8875)/23.90381 = -1.87
-> y' = 5.3636

Neden mi Scaling?
* Birimleri ortaklamak için. ML algoritmalarý 250 cm'i 2.5 m'ye göre daha büyük bir þey sanýyor.
* Benzer verileri ortaklýyor ve normalize ediyor.

Naive Bayes
* Stable
* Kategori tespiti, her verinin kategorisi var.
* Veriler öðretilmiþ. Ne kadar çok veri, o kadar iyi.
* Veri tipine göre deðil, oransal iliþkiye bakýyor. => Multinomial

Chinese-Chinese-Ist-Chinese-Tokyo-Japanese

P(Ç)*P(Chinese|Ç)*P(Chinese|Ç)*P(Ist|Ç)*P(Chinese|Ç)*P(Tokyo|Ç)*P(Japanese|Ç) = Ç gelme olasýlýðý

P(Chinese|Ç)=(Ç'deki Chinese sayýsý+1)/(Ç'deki tüm kelimeler+toplam çeþit)

